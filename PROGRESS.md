# Place Analytics 프로젝트 진행 기록

## 2024-01-14 작업 내역

### 1. Dockerfile 배포 오류 수정
- 문제: `playwright install chromium --with-deps` 에러 (exit code 100)
- 원인: apt 캐시 삭제 후 --with-deps 옵션 사용 불가
- 해결: `--with-deps` 옵션 제거
- 커밋: `7c9b311`

### 2. N3 공식 역공학 및 최적화
- 기존 공식 정확도: 91.23% (R² = -292.65%)
- 새 공식 정확도: 99.16% (R² = 95.80%)
- 변경 파일: `backend/app/ml/predictor.py`
- 커밋: `6945218`

#### 새 N3 공식 (2차 다항식)
```python
n3 = (-0.288554
      + 3.350482 * n1
      + 0.159362 * n2
      + 0.438085 * n1 * n2
      - 3.715231 * n1**2
      - 0.851072 * n2**2)
```

### 3. N1, N2, N3 역공학 분석 결과

#### 정확도 요약
| 지수 | 정확도 | R² | 계산 방식 |
|------|--------|-----|-----------|
| N1 | 99.94% | 99.94% | 키워드별 상수값 |
| N2 | 99.10% | 99.10% | N2 = slope x rank + intercept |
| N3 | 99.97% | 99.97% | N3 = slope x N2 + intercept |

#### N1 키워드별 상수값
| 키워드 | N1 값 |
|--------|-------|
| 강남카페 | 0.3973 |
| 서울반지공방 | 0.4567 |
| 성남맞춤정장 | 0.4684 |
| 성수동맛집 | 0.3669 |
| 이태원술집 | 0.5563 |
| 판교맛집 | 0.3669 |

#### N2 키워드별 파라미터
| 키워드 | 기울기 (slope) | 절편 (intercept) |
|--------|----------------|------------------|
| 강남카페 | -0.00103 | 0.5506 |
| 서울반지공방 | -0.00519 | 0.4752 |
| 성남맞춤정장 | -0.01647 | 0.3807 |
| 성수동맛집 | -0.00100 | 0.5553 |
| 이태원술집 | -0.00209 | 0.5098 |
| 판교맛집 | -0.00138 | 0.5495 |

### 4. ADLOG API 의존성 제거 방안

#### 현재 상태
- ADLOG API에 완전 의존
- 매 요청마다 API 호출 필요

#### 개선 방안
- 키워드별 파라미터 테이블 생성
- 새 키워드만 1회 API 호출하여 파라미터 캐싱
- 이후 로컬 계산으로 N1, N2, N3 산출

#### 전체 파이프라인
```
입력: keyword + rank
  |
Step 1: N1 = keyword_params[keyword].n1_value
Step 2: N2 = keyword_params[keyword].n2_slope x rank + n2_intercept
Step 3: N3 = keyword_params[keyword].n3_slope x N2 + n3_intercept
  |
출력: N1, N2, N3 (99%+ 정확도)
```

---

## 🎯 궁극적 목표 (중요!)

### 현재 한계
- 현재 공식: `순위 → N2 → N3` (순위가 원인, N2가 결과)
- 불가능한 것: `블로그 리뷰 +10개 → N2 얼마나 상승?` (예측 불가)
- 이유: N2는 순위의 "결과"이지, 리뷰/유입수의 "결과"가 아님

### 궁극적으로 달성해야 할 것
```
블로그 리뷰 +10개 → 평균 2순위 상승 → N3 +1.5점
```
이런 패턴을 발견하려면 **시계열 데이터 학습**이 필요함

### 학습 데이터 수집 방법
```
1일차: 블로그 10개, 순위 7위
       ↓ 사용자 입력: "블로그 5개 추가함"
7일차: 블로그 15개, 순위 5위
       ↓
학습: "블로그 +5개 → 2순위 상승" 패턴 발견
```

**핵심: 사용자가 행동을 기입하면 그게 학습 데이터가 됨**

---

## 현재 시뮬레이션 문제점

### 문제 1: 인과관계 역전
- 현재 가정: `리뷰 증가 → N2 상승 → 순위 상승`
- 실제 로직: `순위 → N2 결정` (N2는 순위의 결과)

### 문제 2: 근거 없는 계수
```python
DEFAULT_COEFFICIENTS = {
    "blog_review": 0.002143,   # 근거 없음
    "visit_review": 0.000598,  # 근거 없음
}
```

### 개선 방향
1. ❌ 예약 건수 입력 삭제
2. ✅ 유입수 입력 유지 (경쟁 분석용)
3. 🔄 시뮬레이션: "목표 순위" 기반으로 변경
4. ➕ 사용자 행동 기입 기능 추가 (학습 데이터 수집)

---

## 다음 작업 (TODO)

### Phase 1: 키워드 파라미터 시스템
- [ ] 키워드별 파라미터 저장 테이블 생성
- [ ] ADLOG API 최초 1회 호출 → 파라미터 캐싱
- [ ] 이후 자체 계산으로 N1, N2, N3 산출

### Phase 2: 새벽 자동 학습 시스템
- [ ] trainer.py 구현 (현재 빈 파일)
- [ ] analyzer.py 구현 (현재 빈 파일)
- [ ] 새벽 2시 cron job 설정
- [ ] 수집된 데이터로 공식 계수 자동 최적화

### Phase 3: 시뮬레이션 개선
- [ ] 예약 건수 입력 필드 삭제
- [ ] 목표 순위 기반 시뮬레이션으로 변경
- [ ] 키워드별 순위 상승 시 점수 변화 표시

### Phase 4: 시계열 학습 (궁극적 목표) - **완료!**
- [x] 사용자 행동 기입 기능 추가 ("블로그 5개 추가함")
- [x] 행동 → 순위 변화 상관관계 분석
- [x] "블로그 +N개 → 평균 X순위 상승" 패턴 학습
- [x] 진정한 의미의 시뮬레이션 완성

#### 구현 내용 (2024-01-14)
1. **UserActivityLog 모델** (이미 존재)
   - 블로그 리뷰, 방문자 리뷰, 저장수, 유입수 활동 기록
   - D+1, D+7 결과 추적 필드

2. **Activity API** (`backend/app/api/v1/activity.py`)
   - `POST /activity/log` - 활동 기록
   - `GET /activity/history` - 히스토리 조회
   - `GET /activity/effect-analysis` - 효과 분석
   - `POST /activity/update-results` - D+1/D+7 배치 업데이트

3. **CorrelationAnalyzer** (`backend/app/ml/correlation_analyzer.py`)
   - 활동별 상관관계 분석
   - 회귀분석으로 예측 공식 생성
   - 키워드별 패턴 분석

4. **Frontend 활동 기입 UI** (`inquiry/page.tsx`)
   - "오늘 어떤 작업을 하셨나요?" 섹션
   - 블로그 리뷰, 저장수, 유입수 체크박스 + 개수
   - 경고 배너: "모르거나 안했으면 체크하지 마세요"

---

## 배포 정보
- Frontend: Vercel
- Backend: Render.com
- GitHub: https://github.com/SONGMINSEUNG/place.git
